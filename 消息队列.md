# Kafka

https://segmentfault.com/a/1190000040773392


## [Producer](https://mp.weixin.qq.com/s/AtGyvCRT5cv5jipQxbNPZg)

Producer将客户端的请求打包封装发送到 kafka 集群的某个 Topic 的某个分区上

#### Producer初始化

1)设置分区器(partitioner), 分区器是支持自定义的

2)设置重试时间(retryBackoffMs)默认100ms

3)设置序列化器(Serializer)

4)设置拦截器(interceptors)

5)初始化集群元数据(metadata),刚开始空的

6)设置最大的消息为多大(maxRequestSize), 默认最大1M, 生产环境可以提高到10M

7)设置缓存大小(totalMemorySize) 默认是32M

8)设置压缩格式(compressionType)

9)初始化RecordAccumulator也就是缓冲区指定为32M

10)定时更新(metadata.update)

11)创建NetworkClient

12)创建Sender线程

13)KafkaThread将Sender设置为守护线程并启动


#### 元数据

我们每一个topic，在Kafka是分布式的形式存放的，所以一个topic就会有多个分区，每个分区对应值着不同的ip、端口等信息。所以每个topic有多少分分区，每个分区的leader节点replica节点的ip、端口信息等，也属于元数据Metadata的Cluster

对于生产者客户端来说，这些元数据都是Kafka的信息，所以往kafka发送消息之前，就需要拉取元数据。

![元数据拉取](metadata_get.png)


#### Producer发送消息

1)、进行 Kafka Producer 初始化，加载默认配置以及设置的配置参数，开启网络线程；

2)、执行拦截器逻辑，预处理消息, 封装 Producer Record

3)、调用Serializer.serialize()方法进行消息的key/value序列化

4)、调用partition()选择合适的分区策略，给消息体 Producer Record 分配要发送的 topic 分区号

5)、从 Kafka Broker 集群获取集群元数据metadata

6)、将消息缓存到RecordAccumulator收集器中, 最后判断是否要发送。这个加入消息收集器，首先得从 Deque<RecordBatch> 里找到自己的目标分区，如果没有就新建一个批量消息 Deque 加进入

7)、如果达到发送阈值，唤醒Sender线程，实例化 NetWorkClient 将 batch record 转换成 request client 的发送消息体, 并将待发送的数据按 【Broker Id <=> List】的数据进行归类

8)、与服务端不同的 Broker 建立网络连接，将对应 Broker 待发送的消息 List 发送出去。

9)、批次发送的条件为:缓冲区数据大小达到 batch.size 或者 linger.ms 达到上限，哪个先达到就算哪个

![](send_message.png)


#### 内存池

![](memory_pool.png)


#### 高并发网络

ack策略，同步与异步，幂等性设置，事务设置


#### 参数调优



## [Consumer](https://mp.weixin.qq.com/s/47AKpLzRHhbTUUvNbVxv7w)

#### Push与Pull

+ Push：Broker主动推送，不能感知消费者消费速率

+ Pull：Consumer主动拉取，容易空Poll（可以附上阻塞时间）


#### Consumer初始化和消费

初始化：

+ 构造propertity对象，设置consumer参数

+ 创建Consumer

+ 订阅subscribe topic（不止订阅一个）

+ 循环定时调用poll获取消息并且处理

消费：

![](consume_process.png)


#### 消费者组

Consumer Group 是 Kafka 提供的`横向扩展`且具有容错性的消费者机制。

##### 特点

+ 每个 Consumer Group 有一个或者多个 Consumer

+ 每个 Consumer Group 拥有一个公共且唯一的 Group ID

+ Consumer Group 在消费 Topic 的时候，Topic 的每个 Partition 只能分配给组内的某个 Consumer，只要被任何 Consumer 消费一次, 那么这条数据就可以认为被当前 Consumer Group 消费成功

##### Partition分配

+ RangeAssignor

+ RoundRobinAssignor

+ StickyAssignor


#### 消费者组重分配


#### 消费者offset

##### 自动提交

开始调用 Poll() 方法时，提交上一批消息的位移，再处理下一批消息

在自动提交间隔之间发生 Rebalance 的时候，此时 Offset 还未提交，待 Rebalance 完成后， 所有 Consumer 需要将发生 Rebalance 前的消息进行重新消费一次。

##### 手动提交

+ 同步提交：Poll()方法返回所有消息之后手动调用api进行提交

+ 异步提交：立即返回，使用回调函数，若失败则不能重试

+ 混合提交

##### 存储

格式为 <Group ID，主题名，分区号 > offset

存储在特殊的topic中（也有分区）






## Broker

##### 副本

+ replica

+ AR(Assigned replica)

+ ISR(in sync replica)

+ OSR(out of sync replica)

follower默认每隔500ms向leader fetch一次数据，只要一个Follower副本落后Leader副本的时间不连续超过10秒，则为IR

当leader死了，选举IR之一为leader（OSR通过参数配置后也可以）

##### 主从一致

+ HW(high watermark)

+ LEO(log end offset)

+ Leader HW：min（所有副本LEO），为此Leader副本不仅要保存自己的HW和LEO，还要保存follower副本的HW和LEO，而follower副本只需保存自己的HW和LEO

+ Follower HW：min(follower自身LEO，leader HW)

leader epoch：同raft任期



## 消息与索引存储

每一个partition会被分为多个segment，每当条件满足（时间和partition大小），将会创建新的segment

每个segment对应三个文件：

+ log：消息

+ index：offset to position

+ timeindex：timesnap to offset

[索引的冷区与热区](https://www.modb.pro/db/88205)




## [性能](https://mp.weixin.qq.com/s/kmRnukY5P2GuvaoctyBHQA)

##### 顺序写磁盘和OS cache

##### 零拷贝技术

从 Kafka 的磁盘文件读取数据然后通过网络发送给下游的消费者

使用sendfile系统调用从磁盘直接发送到网卡，不经过用户态

mmap

##### 压缩传输

在 Kafka 中, 压缩可能会发生在两个地方: 生产者端和Broker端,

一句话总结下压缩和解压缩, 即 Producer 端压缩, Broker 端保持, Consumer 端解压缩

##### 内存池与批处理

参考上面

##### 高并发网络设计

参考上面

##### 索引

参考上面















